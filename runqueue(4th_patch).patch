diff --git a/include/linux/sched.h b/include/linux/sched.h
index 04c52cb06..1d91aedbc 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -725,6 +725,12 @@ struct sched_dl_entity {
 #endif
 };
 
+
+struct sched_hvf_entity {
+	struct rb_node run_node;
+	long sched_value;
+};
+
 #ifdef CONFIG_UCLAMP_TASK
 /* Number of utilization clamp buckets (shorter alias) */
 #define UCLAMP_BUCKETS CONFIG_UCLAMP_BUCKETS_COUNT
@@ -851,6 +857,7 @@ struct task_struct {
 	struct sched_rt_entity		rt;
 	struct sched_dl_entity		dl;
 	struct sched_dl_entity		*dl_server;
+	struct sched_hvf_entity		hvf;
 #ifdef CONFIG_SCHED_CLASS_EXT
 	struct sched_ext_entity		scx;
 #endif
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 9eedf6538..82207a522 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -8487,10 +8487,11 @@ void __init sched_init(void)
 #endif
 	BUG_ON(!sched_class_above(&dl_sched_class, &rt_sched_class));
 	BUG_ON(!sched_class_above(&rt_sched_class, &fair_sched_class));
-	BUG_ON(!sched_class_above(&fair_sched_class, &idle_sched_class));
+    BUG_ON(!sched_class_above(&fair_sched_class, &hvf_sched_class));
+    BUG_ON(!sched_class_above(&hvf_sched_class, &idle_sched_class));
 #ifdef CONFIG_SCHED_CLASS_EXT
 	BUG_ON(!sched_class_above(&fair_sched_class, &ext_sched_class));
-	BUG_ON(!sched_class_above(&ext_sched_class, &idle_sched_class));
+    BUG_ON(!sched_class_above(&ext_sched_class, &hvf_sched_class));
 #endif
 
 	wait_bit_init();
@@ -8556,6 +8557,7 @@ void __init sched_init(void)
 		init_cfs_rq(&rq->cfs);
 		init_rt_rq(&rq->rt);
 		init_dl_rq(&rq->dl);
+        init_hvf_rq(&rq->hvf);
 #ifdef CONFIG_FAIR_GROUP_SCHED
 		INIT_LIST_HEAD(&rq->leaf_cfs_rq_list);
 		rq->tmp_alone_branch = &rq->leaf_cfs_rq_list;
diff --git a/kernel/sched/hvf.c b/kernel/sched/hvf.c
index e5ceeed8f..22dca99f7 100644
--- a/kernel/sched/hvf.c
+++ b/kernel/sched/hvf.c
@@ -1,7 +1,18 @@
 #include <linux/sched.h>
+#include <linux/rbtree.h>
+#include <linux/cpumask.h>
+#include <linux/types.h>
+#include <linux/timekeeping.h>
 #include <asm-generic/errno.h>
 #include "sched.h"
 
+#define M 1000
+#define H 100
+
+
+long compute_sched_value(struct task_struct *p);
+
+
 const struct sched_class hvf_sched_class;
 
 
@@ -11,3 +22,24 @@ const struct sched_class hvf_sched_class;
 DEFINE_SCHED_CLASS(hvf)={
 
 };
+
+
+
+void init_hvf_rq(struct hvf_rq *hvf_rq){
+	hvf_rq->hvf_task_queue = RB_ROOT;
+	hvf_rq->max_value_entity = NULL;
+
+}
+
+long compute_sched_value(struct task_struct *p){
+	struct timespec64 now;
+	ktime_get_real_ts64(&now);
+	const long D1 = p->deadline_1*M;
+	const long D2 = p->deadline_2*M;
+	const long X = now.tv_sec*M+p->computation_time;
+	const long V = (X<D1)? H : (D2<X)? 0 : (D2-X)*H/(D2-D1);
+
+	p->hvf.sched_value = V;
+
+	return V;
+}
diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h
index 9de703227..ffa5786fe 100644
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@ -78,6 +78,7 @@
 struct rq;
 struct cfs_rq;
 struct rt_rq;
+struct hvf_rq;
 struct sched_group;
 struct cpuidle_state;
 
@@ -653,6 +654,14 @@ struct balance_callback {
 	void (*func)(struct rq *rq);
 };
 
+/* HVF-related fields in a runqueue */
+
+struct hvf_rq {
+	struct rb_root	hvf_task_queue;
+	struct sched_hvf_entity *max_value_entity;
+};
+
+
 /* CFS-related fields in a runqueue */
 struct cfs_rq {
 	struct load_weight	load;
@@ -1141,6 +1150,7 @@ struct rq {
 	struct cfs_rq		cfs;
 	struct rt_rq		rt;
 	struct dl_rq		dl;
+	struct hvf_rq		hvf;
 #ifdef CONFIG_SCHED_CLASS_EXT
 	struct scx_rq		scx;
 #endif
@@ -2721,6 +2731,7 @@ extern void update_max_interval(void);
 extern void init_sched_dl_class(void);
 extern void init_sched_rt_class(void);
 extern void init_sched_fair_class(void);
+extern void init_sched_hvf_class(void);
 
 extern void resched_curr(struct rq *rq);
 extern void resched_curr_lazy(struct rq *rq);
@@ -3193,6 +3204,7 @@ static inline void resched_latency_warn(int cpu, u64 latency) { }
 extern void init_cfs_rq(struct cfs_rq *cfs_rq);
 extern void init_rt_rq(struct rt_rq *rt_rq);
 extern void init_dl_rq(struct dl_rq *dl_rq);
+extern void init_hvf_rq(struct hvf_rq *hvf_rq);
 
 extern void cfs_bandwidth_usage_inc(void);
 extern void cfs_bandwidth_usage_dec(void);
diff --git a/kernel/sched/hvf.c b/kernel/sched/hvf.c
index 22dca99f7..e0e95a3c5 100644
--- a/kernel/sched/hvf.c
+++ b/kernel/sched/hvf.c
@@ -11,6 +11,8 @@
 
 
 long compute_sched_value(struct task_struct *p);
+bool hvf_rq_rbtree_insert(struct rb_root *root, struct sched_hvf_entity *se);
+
 
 
 const struct sched_class hvf_sched_class;
@@ -43,3 +45,24 @@ long compute_sched_value(struct task_struct *p){
 
 	return V;
 }
+
+
+bool hvf_rq_rbtree_insert(struct rb_root *root, struct sched_hvf_entity *se){
+	struct rb_node **new_node = &(root->rb_node), *parent = NULL;
+
+	while(*new_node!=NULL){
+		struct sched_hvf_entity *this_entity = container_of(*new_node, struct sched_hvf_entity, run_node);
+		int result = se->sched_value - this_entity->sched_value;
+
+		parent = *new_node;
+		if(result<=0)
+			new_node = &((*new_node)->rb_left);
+		else
+			new_node = &((*new_node)->rb_right);
+	}
+
+	rb_link_node(&se->run_node, parent, new_node);
+	rb_insert_color(&se->run_node, root);
+
+	return true;
+}
diff --git a/kernel/sched/hvf.c b/kernel/sched/hvf.c
index e0e95a3c5..b41c54fc9 100644
--- a/kernel/sched/hvf.c
+++ b/kernel/sched/hvf.c
@@ -17,12 +17,15 @@ bool hvf_rq_rbtree_insert(struct rb_root *root, struct sched_hvf_entity *se);
 
 const struct sched_class hvf_sched_class;
 
+static void
+enqueue_task_hvf(struct rq *rq, struct task_struct *p, int flags){
 
+}
 
 
 
 DEFINE_SCHED_CLASS(hvf)={
-
+	.enqueue_task = enqueue_task_hvf
 };
 
 
@@ -30,7 +33,6 @@ DEFINE_SCHED_CLASS(hvf)={
 void init_hvf_rq(struct hvf_rq *hvf_rq){
 	hvf_rq->hvf_task_queue = RB_ROOT;
 	hvf_rq->max_value_entity = NULL;
-
 }
 
 long compute_sched_value(struct task_struct *p){
@@ -66,3 +68,7 @@ bool hvf_rq_rbtree_insert(struct rb_root *root, struct sched_hvf_entity *se){
 
 	return true;
 }
+
+
+
+
diff --git a/kernel/sched/hvf.c b/kernel/sched/hvf.c
index b41c54fc9..110c3bca6 100644
--- a/kernel/sched/hvf.c
+++ b/kernel/sched/hvf.c
@@ -17,6 +17,14 @@ bool hvf_rq_rbtree_insert(struct rb_root *root, struct sched_hvf_entity *se);
 
 const struct sched_class hvf_sched_class;
 
+inline void atomic_insert(struct rq *rq, struct sched_hvf_entity *se){
+	struct rq_flags flags;
+	rq_lock(rq, &flags);
+	hvf_rq_rbtree_insert(&rq->hvf.hvf_task_queue, se);
+	rq->hvf.max_value_entity = rb_entry(rb_first(&rq->hvf.hvf_task_queue), struct sched_hvf_entity, run_node);
+	rq_unlock(rq, &flags);
+}
+
 static void
 enqueue_task_hvf(struct rq *rq, struct task_struct *p, int flags){
 
